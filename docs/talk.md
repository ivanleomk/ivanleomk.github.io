# Talks

I mostly talk about Structured Outputs, Open Source work and working with Language Models. Here's a collection of talks and presentations I've given so far.

## February 2025

- [21 February : AI Engineering Summit New York](https://www.ai.engineer/summit/2025) : I was invited down to speak about how we can use synthetic data for evaluations with RAG Applications and why a systematic approach to evaluations is important for building reliable LLM applications. You can view the notebooks that I used in the talk [here](https://github.com/567-labs/ai-engineering-summit)

- [4 February - Structured Outputs and OSS](https://ivanleomk.quarto.pub/structured-outputs-and-oss/#/title-slide) : I spoke about my experience working with Open Source, the importance of structured outputs, how to use binary metrics for quick iteration and how synthetic data can be used to evaluate LLM applications.

## January 2025

- [January 24 - Building Reliable LLM Applications](./blog/posts/building-reliable-llm-applications.md) : I was invited down to NUS to speak about my experience working on open source frameworks like instructor and how we can use binary metrics,synthetic data and structured outputs to catch errors before we ship to production.

- [January 10 - Open CLIO](./blog/posts/clio.md) : I presented on an open source project I'm working on called [Kura](https://github.com/ivanleomk/kura/) which is a tool for helping to analyse and understand user feedback from LLM Applications at a [local AI Tinkerers meetup](https://singapore.aitinkerers.org/talks/rsvp_6Vn-sgOQb4Y)

## Dec 2024

- [December 9 - How to Tame Your LLM Application](./blog/posts/taming-your-llm-application.md) : I spoke briefly about some of the various stages that we go through when we build a LLM application and how we can progressively improve our application from a simple prompt to a more complex and reliable one with structured outputs, binary metrics and more.
