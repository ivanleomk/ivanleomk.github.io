<!--
  Copyright (c) 2016-2024 Martin Donath <martin.donath@squidfunk.com>

  Permission is hereby granted, free of charge, to any person obtaining a copy
  of this software and associated documentation files (the "Software"), to
  deal in the Software without restriction, including without limitation the
  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
  sell copies of the Software, and to permit persons to whom the Software is
  furnished to do so, subject to the following conditions:

  The above copyright notice and this permission notice shall be included in
  all copies or substantial portions of the Software.

  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE
  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
  IN THE SOFTWARE.
--> <!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="How to start shipping more reliable LLM applications to prod"><link rel=canonical href=https://ivanleo.com/blog/taming-your-llm-application.html><link rel=prev href=are-your-eval-improvements-just-pure-chance.html><link rel=next href=what-it-means-to-look-at-your-data.html><link rel=alternate type=application/rss+xml title="RSS feed" href=../feed_rss_created.xml><link rel=alternate type=application/rss+xml title="RSS feed of updated content" href=../feed_rss_updated.xml><link rel=icon href=../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.5.44"><title>Taming Your LLM Application - Ivan's Blog</title><link rel=stylesheet href=../assets/stylesheets/main.0253249f.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../assets/_mkdocstrings.css><script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-MM8QMY5JWN"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-MM8QMY5JWN",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-MM8QMY5JWN",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><meta property=og:type content=website><meta property=og:title content="Taming Your LLM Application - Ivan's Blog"><meta property=og:description content="How to start shipping more reliable LLM applications to prod"><meta property=og:image content=https://ivanleo.com/assets/images/social/blog/posts/taming-your-llm-application.png><meta property=og:image:type content=image/png><meta property=og:image:width content=1200><meta property=og:image:height content=630><meta property=og:url content=https://ivanleo.com/blog/taming-your-llm-application.html><meta name=twitter:card content=summary_large_image><meta name=twitter:title content="Taming Your LLM Application - Ivan's Blog"><meta name=twitter:description content="How to start shipping more reliable LLM applications to prod"><meta name=twitter:image content=https://ivanleo.com/assets/images/social/blog/posts/taming-your-llm-application.png></head> <body dir=ltr> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#taming-your-llm-application class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../index.html title="Ivan's Blog" class="md-header__button md-logo" aria-label="Ivan's Blog" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Ivan's Blog </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Taming Your LLM Application </span> </div> </div> </div> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../index.html class=md-tabs__link> About me </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=index.html class=md-tabs__link> Blog </a> </li> <li class=md-tabs__item> <a href=../work.html class=md-tabs__link> Work with me </a> </li> <li class=md-tabs__item> <a href=../newsletter.html class=md-tabs__link> Newsletter </a> </li> <li class=md-tabs__item> <a href=../talk.html class=md-tabs__link> Talks </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation hidden> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../index.html title="Ivan's Blog" class="md-nav__button md-logo" aria-label="Ivan's Blog" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> Ivan's Blog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../index.html class=md-nav__link> <span class=md-ellipsis> About me </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2 checked> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex> <span class=md-ellipsis> Blog </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Blog </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <a href=index.html class=md-nav__link> <span class=md-ellipsis> Index </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2> <label class=md-nav__link for=__nav_2_2 id=__nav_2_2_label tabindex=0> <span class=md-ellipsis> Archive </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2> <span class="md-nav__icon md-icon"></span> Archive </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=archive/2025.html class=md-nav__link> <span class=md-ellipsis> 2025 </span> </a> </li> <li class=md-nav__item> <a href=archive/2024.html class=md-nav__link> <span class=md-ellipsis> 2024 </span> </a> </li> <li class=md-nav__item> <a href=archive/2023.html class=md-nav__link> <span class=md-ellipsis> 2023 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3> <label class=md-nav__link for=__nav_2_3 id=__nav_2_3_label tabindex=0> <span class=md-ellipsis> Categories </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3> <span class="md-nav__icon md-icon"></span> Categories </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=category/ai.html class=md-nav__link> <span class=md-ellipsis> AI </span> </a> </li> <li class=md-nav__item> <a href=category/ai-engineering.html class=md-nav__link> <span class=md-ellipsis> AI Engineering </span> </a> </li> <li class=md-nav__item> <a href=category/advice.html class=md-nav__link> <span class=md-ellipsis> Advice </span> </a> </li> <li class=md-nav__item> <a href=category/applied-ai.html class=md-nav__link> <span class=md-ellipsis> Applied AI </span> </a> </li> <li class=md-nav__item> <a href=category/braintrust.html class=md-nav__link> <span class=md-ellipsis> Braintrust </span> </a> </li> <li class=md-nav__item> <a href=category/career.html class=md-nav__link> <span class=md-ellipsis> Career </span> </a> </li> <li class=md-nav__item> <a href=category/clustering.html class=md-nav__link> <span class=md-ellipsis> Clustering </span> </a> </li> <li class=md-nav__item> <a href=category/comfyui.html class=md-nav__link> <span class=md-ellipsis> ComfyUI </span> </a> </li> <li class=md-nav__item> <a href=category/debugging.html class=md-nav__link> <span class=md-ellipsis> Debugging </span> </a> </li> <li class=md-nav__item> <a href=category/deployment.html class=md-nav__link> <span class=md-ellipsis> Deployment </span> </a> </li> <li class=md-nav__item> <a href=category/diffusion-models.html class=md-nav__link> <span class=md-ellipsis> Diffusion Models </span> </a> </li> <li class=md-nav__item> <a href=category/documentation.html class=md-nav__link> <span class=md-ellipsis> Documentation </span> </a> </li> <li class=md-nav__item> <a href=category/evals.html class=md-nav__link> <span class=md-ellipsis> Evals </span> </a> </li> <li class=md-nav__item> <a href=category/evaluation.html class=md-nav__link> <span class=md-ellipsis> Evaluation </span> </a> </li> <li class=md-nav__item> <a href=category/evaluations.html class=md-nav__link> <span class=md-ellipsis> Evaluations </span> </a> </li> <li class=md-nav__item> <a href=category/instructor.html class=md-nav__link> <span class=md-ellipsis> Instructor </span> </a> </li> <li class=md-nav__item> <a href=category/llm.html class=md-nav__link> <span class=md-ellipsis> LLM </span> </a> </li> <li class=md-nav__item> <a href=category/llms.html class=md-nav__link> <span class=md-ellipsis> LLMs </span> </a> </li> <li class=md-nav__item> <a href=category/mcps.html class=md-nav__link> <span class=md-ellipsis> MCPs </span> </a> </li> <li class=md-nav__item> <a href=category/mac.html class=md-nav__link> <span class=md-ellipsis> Mac </span> </a> </li> <li class=md-nav__item> <a href=category/machine-learning.html class=md-nav__link> <span class=md-ellipsis> Machine Learning </span> </a> </li> <li class=md-nav__item> <a href=category/modal.html class=md-nav__link> <span class=md-ellipsis> Modal </span> </a> </li> <li class=md-nav__item> <a href=category/personal.html class=md-nav__link> <span class=md-ellipsis> Personal </span> </a> </li> <li class=md-nav__item> <a href=category/personal-development.html class=md-nav__link> <span class=md-ellipsis> Personal Development </span> </a> </li> <li class=md-nav__item> <a href=category/python.html class=md-nav__link> <span class=md-ellipsis> Python </span> </a> </li> <li class=md-nav__item> <a href=category/rag.html class=md-nav__link> <span class=md-ellipsis> RAG </span> </a> </li> <li class=md-nav__item> <a href=category/rwkv.html class=md-nav__link> <span class=md-ellipsis> RWKV </span> </a> </li> <li class=md-nav__item> <a href=category/synthetic-data.html class=md-nav__link> <span class=md-ellipsis> Synthetic Data </span> </a> </li> <li class=md-nav__item> <a href=category/testing.html class=md-nav__link> <span class=md-ellipsis> Testing </span> </a> </li> <li class=md-nav__item> <a href=category/trends.html class=md-nav__link> <span class=md-ellipsis> Trends </span> </a> </li> <li class=md-nav__item> <a href=category/ui-generation.html class=md-nav__link> <span class=md-ellipsis> UI Generation </span> </a> </li> <li class=md-nav__item> <a href=category/uiux.html class=md-nav__link> <span class=md-ellipsis> UI/UX </span> </a> </li> <li class=md-nav__item> <a href=category/voice.html class=md-nav__link> <span class=md-ellipsis> Voice </span> </a> </li> <li class=md-nav__item> <a href=category/walkthrough.html class=md-nav__link> <span class=md-ellipsis> Walkthrough </span> </a> </li> <li class=md-nav__item> <a href=category/whisper.html class=md-nav__link> <span class=md-ellipsis> Whisper </span> </a> </li> <li class=md-nav__item> <a href=category/langchain.html class=md-nav__link> <span class=md-ellipsis> langchain </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../work.html class=md-nav__link> <span class=md-ellipsis> Work with me </span> </a> </li> <li class=md-nav__item> <a href=../newsletter.html class=md-nav__link> <span class=md-ellipsis> Newsletter </span> </a> </li> <li class=md-nav__item> <a href=../talk.html class=md-nav__link> <span class=md-ellipsis> Talks </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#five-levels-of-llm-applications class=md-nav__link> <span class=md-ellipsis> Five levels of LLM Applications </span> </a> <nav class=md-nav aria-label="Five levels of LLM Applications"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#structured-outputs class=md-nav__link> <span class=md-ellipsis> Structured Outputs </span> </a> </li> <li class=md-nav__item> <a href=#prioritizing-iteration class=md-nav__link> <span class=md-ellipsis> Prioritizing Iteration </span> </a> </li> <li class=md-nav__item> <a href=#synthetic-data class=md-nav__link> <span class=md-ellipsis> Synthetic Data </span> </a> </li> <li class=md-nav__item> <a href=#segmentation class=md-nav__link> <span class=md-ellipsis> Segmentation </span> </a> </li> <li class=md-nav__item> <a href=#qualitative-evaluation class=md-nav__link> <span class=md-ellipsis> Qualitative Evaluation </span> </a> <nav class=md-nav aria-label="Qualitative Evaluation"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#weak-label-generation class=md-nav__link> <span class=md-ellipsis> Weak Label Generation </span> </a> </li> <li class=md-nav__item> <a href=#style-and-quality-assessment class=md-nav__link> <span class=md-ellipsis> Style and Quality Assessment </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#conclusion class=md-nav__link> <span class=md-ellipsis> Conclusion </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-content md-content--post" data-md-component=content> <!-- Sidebar --> <div class="md-sidebar md-sidebar--post" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class="md-sidebar__inner md-post"> <nav class="md-nav md-nav--primary"> <!-- Back to overview link --> <div class=md-post__back> <div class="md-nav__title md-nav__container"> <a href=index.html class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> <span class=md-ellipsis> Back to index </span> </a> </div> </div> <div class="md-post__authors md-typeset"> <div class="md-profile md-post__profile"> <span class="md-author md-author--long"> <img src=https://pbs.twimg.com/profile_images/1838778744468836353/utYfioiO_400x400.jpg alt="Ivan Leo"> </span> <span class=md-profile__description> <strong> <a href="https://twitter.com/intent/follow?screen_name=ivanleomk">Ivan Leo</a> </strong> <br> Research Engineer at 567 Labs </span> </div> </div> <!-- Post metadata --> <ul class="md-post__meta md-nav__list"> <li class="md-nav__item md-nav__item--section"> <div class=md-post__title> <span class=md-ellipsis> Metadata </span> </div> <nav class=md-nav> <ul class=md-nav__list> <!-- Post date --> <li class=md-nav__item> <div class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 19H5V8h14m-3-7v2H8V1H6v2H5c-1.11 0-2 .89-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2h-1V1m-1 11h-5v5h5z"/></svg> <time datetime="2024-12-05 00:00:00" class=md-ellipsis>December 5, 2024</time> </div> </li> <!-- Post date updated --> <!-- Post categories --> <li class=md-nav__item> <div class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9 3v15h3V3zm3 2 4 13 3-1-4-13zM5 5v13h3V5zM3 19v2h18v-2z"/></svg> <span class=md-ellipsis> in <a href=category/llms.html>LLMs</a>, <a href=category/testing.html>Testing</a>, <a href=category/evaluation.html>Evaluation</a></span> </div> </li> <!-- Post readtime --> <li class=md-nav__item> <div class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 20a8 8 0 0 0 8-8 8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8m0-18a10 10 0 0 1 10 10 10 10 0 0 1-10 10C6.47 22 2 17.5 2 12A10 10 0 0 1 12 2m.5 5v5.25l4.5 2.67-.75 1.23L11 13V7z"/></svg> <span class=md-ellipsis> 11 min read </span> </div> </li> </ul> </nav> </li> </ul> </nav> <!-- Table of contents, if integrated --> </div> </div> </div> <!-- Page content --> <article class="md-content__inner md-typeset"> <h1 id=taming-your-llm-application>Taming Your LLM Application</h1> <blockquote> <p>This is an article that sums up a talk I'm giving in Kaoshiung at the <a href=https://guild.host/events/hackerhouse-taiwan-kaohsiung-r34h1r>Taiwan Hackerhouse Meetup</a> on Dec 9th. If you're interested in attending, you can sign up <a href=https://guild.host/events/hackerhouse-taiwan-kaohsiung-r34h1r>here</a></p> </blockquote> <p>When building LLM applications, teams often jump straight to complex evaluations - using tools like RAGAS or another LLM as a judge. While these sophisticated approaches have their place, I've found that starting with simple, measurable metrics leads to more reliable systems that improve steadily over time.</p> <h2 id=five-levels-of-llm-applications>Five levels of LLM Applications</h2> <p>I think there are five levels that teams seem to progress through as they build more reliable language model applications.</p> <ol> <li>Structured Outputs - Move from raw text to validated data structures</li> <li>Prioritizing Iteration - Using cheap metrics like recall/mrr to ensure you're nailing down the basics</li> <li>Fuzzing - Using synthetic data to systmetically test for edge cases</li> <li>Segmentation - Understanding the weak points of your model</li> <li>LLM Judges - Using LLM as a judge to evaluate subjective aspects</li> </ol> <p>Let's explore each level in more detail and see how they fit into a progression. We'll use <code>instructor</code> in these examples since that's what I'm most familiar with, but the concepts can be applied to other tools as well.</p> <!-- more --> <h3 id=structured-outputs>Structured Outputs</h3> <p><img alt="structured outputs" src=images/llm_meme.png></p> <p>By using structured outputs, we don't need to deal with all the complex prompting tips that we've seen in the past. Instead, we can use a model that's either specifically trained to output valid JSON ( function calling ) or has some other way to ensure the output is valid.</p> <p>If you're using local models, <code>outlines</code> is a great tool for this but if not, I highly suggest <code>instructor</code> for its wide coverage of LLM providers. Let's see it in action.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=kn>import</span> <span class=nn>instructor</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=kn>from</span> <span class=nn>pydantic</span> <span class=kn>import</span> <span class=n>BaseModel</span>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=kn>from</span> <span class=nn>openai</span> <span class=kn>import</span> <span class=n>OpenAI</span>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a><span class=c1># Define your desired output structure</span>
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a><span class=k>class</span> <span class=nc>UserInfo</span><span class=p>(</span><span class=n>BaseModel</span><span class=p>):</span>
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a>    <span class=n>name</span><span class=p>:</span> <span class=nb>str</span>
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a>    <span class=n>age</span><span class=p>:</span> <span class=nb>int</span>
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a>
</span><span id=__span-0-10><a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a><span class=c1># Patch the OpenAI client</span>
</span><span id=__span-0-11><a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a><span class=n>client</span> <span class=o>=</span> <span class=n>instructor</span><span class=o>.</span><span class=n>from_openai</span><span class=p>(</span><span class=n>OpenAI</span><span class=p>())</span>
</span><span id=__span-0-12><a id=__codelineno-0-12 name=__codelineno-0-12 href=#__codelineno-0-12></a>
</span><span id=__span-0-13><a id=__codelineno-0-13 name=__codelineno-0-13 href=#__codelineno-0-13></a><span class=c1># Extract structured data from natural language</span>
</span><span id=__span-0-14><a id=__codelineno-0-14 name=__codelineno-0-14 href=#__codelineno-0-14></a><span class=n>user_info</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span><span id=__span-0-15><a id=__codelineno-0-15 name=__codelineno-0-15 href=#__codelineno-0-15></a>    <span class=n>model</span><span class=o>=</span><span class=s2>&quot;gpt-3.5-turbo&quot;</span><span class=p>,</span>
</span><span id=__span-0-16><a id=__codelineno-0-16 name=__codelineno-0-16 href=#__codelineno-0-16></a>    <span class=n>response_model</span><span class=o>=</span><span class=n>UserInfo</span><span class=p>,</span>
</span><span id=__span-0-17><a id=__codelineno-0-17 name=__codelineno-0-17 href=#__codelineno-0-17></a>
</span><span id=__span-0-18><a id=__codelineno-0-18 name=__codelineno-0-18 href=#__codelineno-0-18></a>    <span class=n>messages</span><span class=o>=</span><span class=p>[{</span><span class=s2>&quot;role&quot;</span><span class=p>:</span> <span class=s2>&quot;user&quot;</span><span class=p>,</span> <span class=s2>&quot;content&quot;</span><span class=p>:</span> <span class=s2>&quot;John Doe is 30 years old.&quot;</span><span class=p>}],</span>
</span><span id=__span-0-19><a id=__codelineno-0-19 name=__codelineno-0-19 href=#__codelineno-0-19></a><span class=p>)</span>
</span><span id=__span-0-20><a id=__codelineno-0-20 name=__codelineno-0-20 href=#__codelineno-0-20></a>
</span><span id=__span-0-21><a id=__codelineno-0-21 name=__codelineno-0-21 href=#__codelineno-0-21></a><span class=nb>print</span><span class=p>(</span><span class=n>user_info</span><span class=o>.</span><span class=n>name</span><span class=p>)</span>
</span><span id=__span-0-22><a id=__codelineno-0-22 name=__codelineno-0-22 href=#__codelineno-0-22></a><span class=c1>#&gt; John Doe</span>
</span><span id=__span-0-23><a id=__codelineno-0-23 name=__codelineno-0-23 href=#__codelineno-0-23></a><span class=nb>print</span><span class=p>(</span><span class=n>user_info</span><span class=o>.</span><span class=n>age</span><span class=p>)</span>
</span><span id=__span-0-24><a id=__codelineno-0-24 name=__codelineno-0-24 href=#__codelineno-0-24></a><span class=c1>#&gt; 30</span>
</span></code></pre></div> <p>I'd like to point out a few things here</p> <ol> <li>We define a Pydantic model as the output - we don't need to handle the provider specific implementation details</li> <li>We prompt the model and provide the details for the output</li> <li>The final output is a validated python object</li> </ol> <p>That's a lot of value already! We don't need to do any prompting to get this behaviour. Yes, our model might struggle with more complex structures but for most response types that have at most 1-2 layers of nesting, most modern models will do a great job.</p> <p>This is great for 3 main reasons</p> <ol> <li><strong>Wide Support</strong> : All major providers support structured outputs in some form. OpenAI has its structured outputs, Google's Gemini has its <a href=https://ai.google.dev/gemini-api/docs/function-calling>function calling</a> while Anthropic has its <a href=https://docs.anthropic.com/en/docs/build-with-claude/tool-use>tool use</a></li> <li><strong>Reliability</strong> : By working with models and systems trained to output valid JSON, we can avoid the pitfalls of complex prompting. Better yet, by using a library like <code>instructor</code>, we can experiment with different response models and see how they perform. <a href=https://python.useinstructor.com/blog/2024/09/26/bad-schemas-could-break-your-llm-structured-outputs/ >Function Calling is much more consistent and reliable than JSON mode from experiments I've ran</a>.</li> <li><strong>Metrics</strong> : Structured outputs give you your first real metrics - success rate. You'll frequently find that this is where Open Source models start to struggle a bit sometimes (Eg. Llama-3.1-70b) relative to closed source models that have infrastructure in place around them.</li> </ol> <p>This makes it easy to integrate existing LLM calls into existing systems and workflows that we've built over time, log data in a structured format and remove a class of parsing errors that we'd otherwise have to deal with.</p> <p>And all it took was just a simple <code>response_model</code> parameter and a <code>.from_openai</code> method.</p> <h3 id=prioritizing-iteration>Prioritizing Iteration</h3> <p>A LLM system is a complex beast with a lot of parts. Even a simple RAG chatbot has a few different components</p> <ol> <li><strong>Retrieval</strong> : This retrieves the relevant documents from some database - most commonly a vector database</li> <li><strong>Generation</strong> : This is how we generate a response from the documents</li> <li><strong>Data Ingestion</strong> : How we're taking the raw data that we're ingesting and converting it into a format that we can use for retrieval</li> </ol> <p>Instead of focusing on evaluating the generated response of the language model, starting with something like retrieval gives us a lot of bang for our buck.</p> <p>It's important here to note that we're not saying that qualitative metrics don't matter (Eg. the style and tone of your final generation ), we're saying that you need to get the basic right and find areas that you can iterate fast.</p> <p>Good metrics here are recall and mrr. If you don't have existing user queries, we can use synthetic data here to generate some queries and see how well we're doing ( <a href=why-user-intent-matters-the-most-for-synthetic-data.html>I wrote a longer guide here on how to generate synthetic queries here with user intent in mind</a> )</p> <p>This doesn't have to be complicated, let's say given a following chunk</p> <div class="language-text highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a>Taiwan is a lovely island which has Chinese as its official language. Their capital is Taipei and the most popular dishes here are beef noodle soup, bubble tea and fried chicken cutlets.
</span></code></pre></div> <p>We can use <code>instructor</code> to generate potential queries simulating user intent</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=kn>import</span> <span class=nn>instructor</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a><span class=kn>from</span> <span class=nn>openai</span> <span class=kn>import</span> <span class=n>OpenAI</span>
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a><span class=kn>from</span> <span class=nn>pydantic</span> <span class=kn>import</span> <span class=n>BaseModel</span>
</span><span id=__span-2-4><a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a><span class=kn>from</span> <span class=nn>rich</span> <span class=kn>import</span> <span class=nb>print</span>
</span><span id=__span-2-5><a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a>
</span><span id=__span-2-6><a id=__codelineno-2-6 name=__codelineno-2-6 href=#__codelineno-2-6></a><span class=n>client</span> <span class=o>=</span> <span class=n>instructor</span><span class=o>.</span><span class=n>from_openai</span><span class=p>(</span><span class=n>OpenAI</span><span class=p>())</span>
</span><span id=__span-2-7><a id=__codelineno-2-7 name=__codelineno-2-7 href=#__codelineno-2-7></a>
</span><span id=__span-2-8><a id=__codelineno-2-8 name=__codelineno-2-8 href=#__codelineno-2-8></a>
</span><span id=__span-2-9><a id=__codelineno-2-9 name=__codelineno-2-9 href=#__codelineno-2-9></a><span class=k>class</span> <span class=nc>Response</span><span class=p>(</span><span class=n>BaseModel</span><span class=p>):</span>
</span><span id=__span-2-10><a id=__codelineno-2-10 name=__codelineno-2-10 href=#__codelineno-2-10></a>    <span class=n>chain_of_thought</span><span class=p>:</span> <span class=nb>str</span>
</span><span id=__span-2-11><a id=__codelineno-2-11 name=__codelineno-2-11 href=#__codelineno-2-11></a>    <span class=n>question</span><span class=p>:</span> <span class=nb>str</span>
</span><span id=__span-2-12><a id=__codelineno-2-12 name=__codelineno-2-12 href=#__codelineno-2-12></a>    <span class=n>answer</span><span class=p>:</span> <span class=nb>str</span>
</span><span id=__span-2-13><a id=__codelineno-2-13 name=__codelineno-2-13 href=#__codelineno-2-13></a>
</span><span id=__span-2-14><a id=__codelineno-2-14 name=__codelineno-2-14 href=#__codelineno-2-14></a>
</span><span id=__span-2-15><a id=__codelineno-2-15 name=__codelineno-2-15 href=#__codelineno-2-15></a><span class=n>chunk</span> <span class=o>=</span> <span class=s2>&quot;&quot;&quot;</span>
</span><span id=__span-2-16><a id=__codelineno-2-16 name=__codelineno-2-16 href=#__codelineno-2-16></a><span class=s2>Taiwan is a lovely island which has Chinese as its official language. Their capital is</span>
</span><span id=__span-2-17><a id=__codelineno-2-17 name=__codelineno-2-17 href=#__codelineno-2-17></a><span class=s2>Taipei and the most popular dishes here are beef noodle soup, bubble tea and fried</span>
</span><span id=__span-2-18><a id=__codelineno-2-18 name=__codelineno-2-18 href=#__codelineno-2-18></a><span class=s2>chicken cutlets.</span>
</span><span id=__span-2-19><a id=__codelineno-2-19 name=__codelineno-2-19 href=#__codelineno-2-19></a><span class=s2>&quot;&quot;&quot;</span>
</span><span id=__span-2-20><a id=__codelineno-2-20 name=__codelineno-2-20 href=#__codelineno-2-20></a>
</span><span id=__span-2-21><a id=__codelineno-2-21 name=__codelineno-2-21 href=#__codelineno-2-21></a><span class=n>resp</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span><span id=__span-2-22><a id=__codelineno-2-22 name=__codelineno-2-22 href=#__codelineno-2-22></a>    <span class=n>model</span><span class=o>=</span><span class=s2>&quot;gpt-4o-mini&quot;</span><span class=p>,</span>
</span><span id=__span-2-23><a id=__codelineno-2-23 name=__codelineno-2-23 href=#__codelineno-2-23></a>    <span class=n>response_model</span><span class=o>=</span><span class=n>Response</span><span class=p>,</span>
</span><span id=__span-2-24><a id=__codelineno-2-24 name=__codelineno-2-24 href=#__codelineno-2-24></a>    <span class=n>messages</span><span class=o>=</span><span class=p>[</span>
</span><span id=__span-2-25><a id=__codelineno-2-25 name=__codelineno-2-25 href=#__codelineno-2-25></a>        <span class=p>{</span>
</span><span id=__span-2-26><a id=__codelineno-2-26 name=__codelineno-2-26 href=#__codelineno-2-26></a>            <span class=s2>&quot;role&quot;</span><span class=p>:</span> <span class=s2>&quot;user&quot;</span><span class=p>,</span>
</span><span id=__span-2-27><a id=__codelineno-2-27 name=__codelineno-2-27 href=#__codelineno-2-27></a>            <span class=s2>&quot;content&quot;</span><span class=p>:</span> <span class=p>(</span>
</span><span id=__span-2-28><a id=__codelineno-2-28 name=__codelineno-2-28 href=#__codelineno-2-28></a>                <span class=s2>&quot;Given the following chunk, generate a question that a user might ask &quot;</span>
</span><span id=__span-2-29><a id=__codelineno-2-29 name=__codelineno-2-29 href=#__codelineno-2-29></a>                <span class=sa>f</span><span class=s2>&quot;which this chunk is uniquely suited to answer? </span><span class=se>\n\n</span><span class=s2> </span><span class=si>{</span><span class=n>chunk</span><span class=si>}</span><span class=s2>&quot;</span>
</span><span id=__span-2-30><a id=__codelineno-2-30 name=__codelineno-2-30 href=#__codelineno-2-30></a>            <span class=p>),</span>
</span><span id=__span-2-31><a id=__codelineno-2-31 name=__codelineno-2-31 href=#__codelineno-2-31></a>        <span class=p>}</span>
</span><span id=__span-2-32><a id=__codelineno-2-32 name=__codelineno-2-32 href=#__codelineno-2-32></a>    <span class=p>],</span>
</span><span id=__span-2-33><a id=__codelineno-2-33 name=__codelineno-2-33 href=#__codelineno-2-33></a><span class=p>)</span>
</span><span id=__span-2-34><a id=__codelineno-2-34 name=__codelineno-2-34 href=#__codelineno-2-34></a>
</span><span id=__span-2-35><a id=__codelineno-2-35 name=__codelineno-2-35 href=#__codelineno-2-35></a><span class=nb>print</span><span class=p>(</span><span class=n>resp</span><span class=p>)</span>
</span><span id=__span-2-36><a id=__codelineno-2-36 name=__codelineno-2-36 href=#__codelineno-2-36></a><span class=c1># &gt; Response(chain_of_thought=&#39;...&#39;, question=&#39;What are some popular dishes in Taiwan?&#39;,</span>
</span><span id=__span-2-37><a id=__codelineno-2-37 name=__codelineno-2-37 href=#__codelineno-2-37></a><span class=c1>#   answer=&#39;...&#39;)</span>
</span></code></pre></div> <p>We can quickly and cheaply generate a lot of these queries, manually review them to see which make sense and then use those to test our retrieval systems. Good metrics here to consider are recall and mrr.</p> <p>Most importantly, we can use these queries to test different approaches to retrieval because we can just run the same queries on each of them and see which performs the best. If we were comparing say - BM25, Vector Search and Vector Search with a Re-Ranker step, we can now identify what the impact on recall, mrr and latency is.</p> <p>Say we generate 100 queries and we find that we get the following results</p> <table> <thead> <tr> <th>Method</th> <th>Recall@5</th> <th>Recall@10</th> <th>Recall@15</th> </tr> </thead> <tbody> <tr> <td>BM25</td> <td>0.72</td> <td>0.78</td> <td>0.82</td> </tr> <tr> <td>Vector Search</td> <td>0.75</td> <td>0.81</td> <td>0.85</td> </tr> <tr> <td>Vector + Re-Ranker</td> <td>0.69</td> <td>0.75</td> <td>0.79</td> </tr> </tbody> </table> <p>We might conclude that for an initial prototype, shipping with BM25 is sufficient because we can match the performance of the other two methods with a simpler system - see how recall@15 for BM25 here matches recall@10 for Vector Search. This means that we can go from absolute recomendations that people give (eg. The BAAI/bge-m3 model is the best model! ) to specific decisions that are unique to our data.</p> <p><strong>But this doesn't just apply to retrieval itself, we can also use this to evaluate our choice of data ingestion method</strong>.</p> <p>Say we were comparing two methods of ingesting data - one that ingest the description of an item and another that ingests the item's description, its price and categories it belongs to. We can use the same set of queries to see which performs the best ( since the underlying chunk doesn't change, just the representation that we're using to embed it ).</p> <p>If we got the following reuslts</p> <table> <thead> <tr> <th>Method</th> <th>Recall@5</th> <th>Recall@10</th> <th>Recall@15</th> </tr> </thead> <tbody> <tr> <td>Description Only</td> <td>0.72</td> <td>0.78</td> <td>0.82</td> </tr> <tr> <td>Description + Price + Categories</td> <td>0.79</td> <td>0.86</td> <td>0.90</td> </tr> </tbody> </table> <p>It's pretty clear here that the second method is better because we get ~10% increase in recall across 5,10 and 15. We've identified an easy win here that takes a small amount of time to implement.</p> <p>Most importantly, we can use these metrics to make a data driven decision about which approach to use. We're not going off some fuzzy <strong>"I think this might work better"</strong>, we know that there's a quantitative objective difference. Since they're cheap and easy to calculate, you can run them multiple times without worrying about cost - locally while developing, in your CI/CD pipelines or even in production.</p> <p>But these aren't just for simple question answering tasks. Good retrieval usually predicts good generation, especially as language models get better.</p> <ul> <li>Text-to-SQL: Look at whether you can retrieve the right tables and relevant code snippets</li> <li>Summarization: See if your model can generate the right citations</li> </ul> <p>and more!</p> <h3 id=synthetic-data>Synthetic Data</h3> <p>Now that you've got a pipeline running, you can use synthetic data to systematically probe your system's behavior. Language models are trained on the entire internet and that means that they understand variations and differences in the data that you might not have considered.</p> <p>Let's say that we're using a LLM on the back to generate search filters in response to a user query and return relevant results to the user.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=kn>import</span> <span class=nn>instructor</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a><span class=kn>from</span> <span class=nn>openai</span> <span class=kn>import</span> <span class=n>OpenAI</span>
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a><span class=kn>from</span> <span class=nn>pydantic</span> <span class=kn>import</span> <span class=n>BaseModel</span>
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a><span class=kn>from</span> <span class=nn>typing</span> <span class=kn>import</span> <span class=n>Optional</span>
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a><span class=kn>from</span> <span class=nn>rich</span> <span class=kn>import</span> <span class=nb>print</span>
</span><span id=__span-3-6><a id=__codelineno-3-6 name=__codelineno-3-6 href=#__codelineno-3-6></a>
</span><span id=__span-3-7><a id=__codelineno-3-7 name=__codelineno-3-7 href=#__codelineno-3-7></a><span class=n>client</span> <span class=o>=</span> <span class=n>instructor</span><span class=o>.</span><span class=n>from_openai</span><span class=p>(</span><span class=n>OpenAI</span><span class=p>())</span>
</span><span id=__span-3-8><a id=__codelineno-3-8 name=__codelineno-3-8 href=#__codelineno-3-8></a>
</span><span id=__span-3-9><a id=__codelineno-3-9 name=__codelineno-3-9 href=#__codelineno-3-9></a>
</span><span id=__span-3-10><a id=__codelineno-3-10 name=__codelineno-3-10 href=#__codelineno-3-10></a><span class=k>class</span> <span class=nc>Filters</span><span class=p>(</span><span class=n>BaseModel</span><span class=p>):</span>
</span><span id=__span-3-11><a id=__codelineno-3-11 name=__codelineno-3-11 href=#__codelineno-3-11></a>    <span class=n>city</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=nb>str</span><span class=p>]</span>
</span><span id=__span-3-12><a id=__codelineno-3-12 name=__codelineno-3-12 href=#__codelineno-3-12></a>    <span class=n>country</span><span class=p>:</span> <span class=nb>str</span>
</span><span id=__span-3-13><a id=__codelineno-3-13 name=__codelineno-3-13 href=#__codelineno-3-13></a>    <span class=n>attraction_categories</span><span class=p>:</span> <span class=nb>list</span><span class=p>[</span><span class=nb>str</span><span class=p>]</span>
</span><span id=__span-3-14><a id=__codelineno-3-14 name=__codelineno-3-14 href=#__codelineno-3-14></a>
</span><span id=__span-3-15><a id=__codelineno-3-15 name=__codelineno-3-15 href=#__codelineno-3-15></a>
</span><span id=__span-3-16><a id=__codelineno-3-16 name=__codelineno-3-16 href=#__codelineno-3-16></a><span class=n>resp</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span><span id=__span-3-17><a id=__codelineno-3-17 name=__codelineno-3-17 href=#__codelineno-3-17></a>    <span class=n>model</span><span class=o>=</span><span class=s2>&quot;gpt-4o-mini&quot;</span><span class=p>,</span>
</span><span id=__span-3-18><a id=__codelineno-3-18 name=__codelineno-3-18 href=#__codelineno-3-18></a>    <span class=n>response_model</span><span class=o>=</span><span class=n>Filters</span><span class=p>,</span>
</span><span id=__span-3-19><a id=__codelineno-3-19 name=__codelineno-3-19 href=#__codelineno-3-19></a>    <span class=n>messages</span><span class=o>=</span><span class=p>[</span>
</span><span id=__span-3-20><a id=__codelineno-3-20 name=__codelineno-3-20 href=#__codelineno-3-20></a>        <span class=p>{</span>
</span><span id=__span-3-21><a id=__codelineno-3-21 name=__codelineno-3-21 href=#__codelineno-3-21></a>            <span class=s2>&quot;role&quot;</span><span class=p>:</span> <span class=s2>&quot;system&quot;</span><span class=p>,</span>
</span><span id=__span-3-22><a id=__codelineno-3-22 name=__codelineno-3-22 href=#__codelineno-3-22></a>            <span class=s2>&quot;content&quot;</span><span class=p>:</span> <span class=s2>&quot;You are a helpful assistant that helps users generate search filters for a travel website to get recomendations on where to go. Make sure that you only include filters that are mentioned in the user&#39;s queries&quot;</span><span class=p>,</span>
</span><span id=__span-3-23><a id=__codelineno-3-23 name=__codelineno-3-23 href=#__codelineno-3-23></a>        <span class=p>},</span>
</span><span id=__span-3-24><a id=__codelineno-3-24 name=__codelineno-3-24 href=#__codelineno-3-24></a>        <span class=p>{</span>
</span><span id=__span-3-25><a id=__codelineno-3-25 name=__codelineno-3-25 href=#__codelineno-3-25></a>            <span class=s2>&quot;role&quot;</span><span class=p>:</span> <span class=s2>&quot;user&quot;</span><span class=p>,</span>
</span><span id=__span-3-26><a id=__codelineno-3-26 name=__codelineno-3-26 href=#__codelineno-3-26></a>            <span class=s2>&quot;content&quot;</span><span class=p>:</span> <span class=s2>&quot;What&#39;s good in Taiwan to do? I generally like exploring temples, musuems and food&quot;</span><span class=p>,</span>
</span><span id=__span-3-27><a id=__codelineno-3-27 name=__codelineno-3-27 href=#__codelineno-3-27></a>        <span class=p>},</span>
</span><span id=__span-3-28><a id=__codelineno-3-28 name=__codelineno-3-28 href=#__codelineno-3-28></a>    <span class=p>],</span>
</span><span id=__span-3-29><a id=__codelineno-3-29 name=__codelineno-3-29 href=#__codelineno-3-29></a><span class=p>)</span>
</span><span id=__span-3-30><a id=__codelineno-3-30 name=__codelineno-3-30 href=#__codelineno-3-30></a>
</span><span id=__span-3-31><a id=__codelineno-3-31 name=__codelineno-3-31 href=#__codelineno-3-31></a><span class=nb>print</span><span class=p>(</span><span class=n>resp</span><span class=p>)</span>
</span><span id=__span-3-32><a id=__codelineno-3-32 name=__codelineno-3-32 href=#__codelineno-3-32></a><span class=c1># &gt; Filters(city=None, country=&#39;Taiwan&#39;, attraction_categories=[&#39;temples&#39;, &#39;museums&#39;, &#39;food&#39;])</span>
</span></code></pre></div> <p>We might want to make sure that our model is able to do the following</p> <ul> <li>In the event that there are no cities mentioned, then only a country should be returned</li> <li>In the event that the user mentions a city, then the city should be populated</li> </ul> <p>We can generate variations of this query and see how well our model does.</p> <div class="language-text highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a>from instructor import from_openai
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a>from openai import OpenAI
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a>from pydantic import BaseModel
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a>import random
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a>
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a>client = from_openai(OpenAI())
</span><span id=__span-4-7><a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a>
</span><span id=__span-4-8><a id=__codelineno-4-8 name=__codelineno-4-8 href=#__codelineno-4-8></a>
</span><span id=__span-4-9><a id=__codelineno-4-9 name=__codelineno-4-9 href=#__codelineno-4-9></a>class RewrittenQuery(BaseModel):
</span><span id=__span-4-10><a id=__codelineno-4-10 name=__codelineno-4-10 href=#__codelineno-4-10></a>    query: str
</span><span id=__span-4-11><a id=__codelineno-4-11 name=__codelineno-4-11 href=#__codelineno-4-11></a>
</span><span id=__span-4-12><a id=__codelineno-4-12 name=__codelineno-4-12 href=#__codelineno-4-12></a>
</span><span id=__span-4-13><a id=__codelineno-4-13 name=__codelineno-4-13 href=#__codelineno-4-13></a>for _ in range(3):
</span><span id=__span-4-14><a id=__codelineno-4-14 name=__codelineno-4-14 href=#__codelineno-4-14></a>    task = random.choice([&quot;mention taipei&quot;, &quot;don&#39;t metion any city&quot;])
</span><span id=__span-4-15><a id=__codelineno-4-15 name=__codelineno-4-15 href=#__codelineno-4-15></a>    resp = client.chat.completions.create(
</span><span id=__span-4-16><a id=__codelineno-4-16 name=__codelineno-4-16 href=#__codelineno-4-16></a>        model=&quot;gpt-4o-mini&quot;,
</span><span id=__span-4-17><a id=__codelineno-4-17 name=__codelineno-4-17 href=#__codelineno-4-17></a>        response_model=RewrittenQuery,
</span><span id=__span-4-18><a id=__codelineno-4-18 name=__codelineno-4-18 href=#__codelineno-4-18></a>        messages=[
</span><span id=__span-4-19><a id=__codelineno-4-19 name=__codelineno-4-19 href=#__codelineno-4-19></a>            {
</span><span id=__span-4-20><a id=__codelineno-4-20 name=__codelineno-4-20 href=#__codelineno-4-20></a>                &quot;role&quot;: &quot;user&quot;,
</span><span id=__span-4-21><a id=__codelineno-4-21 name=__codelineno-4-21 href=#__codelineno-4-21></a>                &quot;content&quot;: f&quot;&quot;&quot;Rewrite this query - What&#39;s good in Taiwan
</span><span id=__span-4-22><a id=__codelineno-4-22 name=__codelineno-4-22 href=#__codelineno-4-22></a>                to do? I generally like exploring temples,
</span><span id=__span-4-23><a id=__codelineno-4-23 name=__codelineno-4-23 href=#__codelineno-4-23></a>                musuems and food -  {task}&quot;&quot;&quot;,
</span><span id=__span-4-24><a id=__codelineno-4-24 name=__codelineno-4-24 href=#__codelineno-4-24></a>            },
</span><span id=__span-4-25><a id=__codelineno-4-25 name=__codelineno-4-25 href=#__codelineno-4-25></a>        ],
</span><span id=__span-4-26><a id=__codelineno-4-26 name=__codelineno-4-26 href=#__codelineno-4-26></a>    )
</span><span id=__span-4-27><a id=__codelineno-4-27 name=__codelineno-4-27 href=#__codelineno-4-27></a>    print(resp)
</span><span id=__span-4-28><a id=__codelineno-4-28 name=__codelineno-4-28 href=#__codelineno-4-28></a>    # &gt; What are some recommended activities in Taiwan? I enjoy exploring temples, museums, and local cuisine.
</span><span id=__span-4-29><a id=__codelineno-4-29 name=__codelineno-4-29 href=#__codelineno-4-29></a>    # &gt; What are some great activities to do in Taipei, Taiwan? I particularly enjoy exploring temples, museums, and trying out local food.
</span><span id=__span-4-30><a id=__codelineno-4-30 name=__codelineno-4-30 href=#__codelineno-4-30></a>    # &gt; What are some recommended activities in Taiwan for someone who enjoys exploring temples, museums, and food?
</span></code></pre></div> <p>This is really useful when it comes to fuzzing your system for edge cases. By having a few different queries that you can test against, you can see how well your system performs for specific use cases.</p> <p>More importantly, you can think of it as</p> <ol> <li>If the model always makes a mistake for a specific type of query, we can add it into the prompt itself with few-shot examples</li> <li>If few-shot examples don't work, then perhaps we can just add a step to reject any queries of type X</li> <li>Maybe this calls for a UI change too?</li> </ol> <p>But more importantly, with these specific queries, we can see that</p> <ul> <li>We're moving away from just testing 3-5 different queries each time and relying on a vibe check</li> <li>We're able to systematically evaluate the impact of different configurations of retrieval method, generation and prompts in our language model ( among other factors )</li> <li>With synthetic data, we can generate a large variety of different queries that we can test against</li> </ul> <p>Ideally we'd want to blend this with real user queries to get a good mix of both over time. We can to be re-generating these queries over time to ensure that we're still perfoming well + our synthetic queries are representative of the queries that users actually ask.</p> <p>If users always ask stuff like "good food taiwan" but your synthetic queries are always long and overly complex like "I'm a solo traveller who likes to explore local food and culture in Taiwan, what are some great food places thT i can visit? I like ... " then you're not going to get a good sense of how well your system is doing.</p> <h3 id=segmentation>Segmentation</h3> <p>The next step once you've started testing your LLM system is to understand its weak points. Specifically, you want to know which portions of your application aren't performing well.</p> <p>This is where you need to do some segmentation and start breaking down your system into different components - This is an article on it's own but basically here's how to think about it</p> <ol> <li>Your application will be a combination of different components</li> <li>Each component will be able to do different things</li> <li>It's not going to score well on everything and so users will complain about it</li> <li>You need to weight the amount of effort required to improve each component + the amount of users that are actually affected by it</li> </ol> <p>If you find that there's a huge problem with how your language model is handling dates for instance but only 2% of users are complaining about it, then perhaps spend your time elsewhere if there are other problems at bay.</p> <h3 id=qualitative-evaluation>Qualitative Evaluation</h3> <p>Language models can serve as powerful judges, particularly in two key areas: generating weak labels and evaluating subjective quality.</p> <h4 id=weak-label-generation>Weak Label Generation</h4> <p>LLMs excel at generating initial "weak" labels that humans can later verify. It's often much faster for humans to validate whether a classification is correct than to create labels from scratch.</p> <p>For example, when building a reranker (as detailed in <a href=https://python.useinstructor.com/blog/2024/10/23/building-an-llm-based-reranker-for-your-rag-pipeline/#defining-the-reranking-models>this instructor.com guide</a>), we can use an LLM to generate initial relevance scores for query-document pairs.</p> <p>Humans can then quickly verify these scores, dramatically speeding up the creation of high-quality training data. This approach works particularly well for tasks like intent classification, content categorization, and topic identification.</p> <h4 id=style-and-quality-assessment>Style and Quality Assessment</h4> <p>Let me revise to keep the links while focusing on the key points:</p> <p>LLMs make great judges in two key ways.</p> <p>First, they're excellent at generating initial "weak" labels that humans can quickly verify - this is way faster (and significantly cheaper) than having humans label everything from scratch. For example, when building a reranker (as detailed in <a href=https://python.useinstructor.com/blog/2024/10/23/building-an-llm-based-reranker-for-your-rag-pipeline/#defining-the-reranking-models>this instructor.com guide</a>), we can use LLMs to generate initial relevance scores that human annotators can rapidly validate.</p> <p>LLMs are also surprisingly good at judging subjective things like writing quality and conversational style, but you have to be smart about it. The key is making it an iterative process - start by having humans rate examples, use those to refine your prompts and evaluation criteria, then keep adjusting based on feedback. <a href=https://blog.vespa.ai/improving-retrieval-with-llm-as-a-judge/ >Vespa's deep dive</a> by Jo offers a great walkthrough of this iterative improvement process.</p> <p>The goal isn't perfect agreement out of the gate, but steady improvement through systematic refinement of how we ask LLMs to judge.</p> <h2 id=conclusion>Conclusion</h2> <p>Building reliable LLM applications is a journey that starts with simple metrics and gradually adds sophistication. This shift allows teams to build systems that improve steadily based on data while keeping evaluation costs manageable.</p> <p>Most importantly, this approach helps transform gut feelings into measurable metrics, enabling data-driven decisions about system improvements rather than relying on vague intuitions about what "feels better." The goal isn't to build a perfect system immediately, but to create one that can be measured, understood, and improved systematically over time.</p> <p>There's a lot more that we can do here, but I hope that this gives you a good starting point for building more reliable LLM applications.</p> <!-- Add social sharing buttons --> <div class=md-social-share style="margin: 2rem 0; text-align: center"> <span class=md-social-share__label style="display: block; margin-bottom: 1rem; font-weight: 500">Share this post:</span> <div class=md-social-share__buttons style="display: flex; gap: 1rem; justify-content: center"> <a href="https://x.com/intent/tweet?text=Taming%20Your%20LLM%20Application&url=https://ivanleo.com/blog/taming-your-llm-application.html" class=md-social-share__button style="
            display: inline-flex;
            align-items: center;
            padding: 0.5rem 1rem;
            border-radius: 4px;
            background: #000;
            color: #fff;
            text-decoration: none;
            transition: opacity 0.2s;
          " target=_blank rel=noopener> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18.901 1.153h3.68l-8.04 9.19L24 22.846h-7.406l-5.8-7.584-6.638 7.584H.474l8.6-9.83L0 1.154h7.594l5.243 6.932ZM17.61 20.644h2.039L6.486 3.24H4.298Z"/></svg> <span style="margin-left: 0.5rem">Share on X</span> </a> <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://ivanleo.com/blog/taming-your-llm-application.html&title=Taming%20Your%20LLM%20Application&summary=&source=" class=md-social-share__button style="
            display: inline-flex;
            align-items: center;
            padding: 0.5rem 1rem;
            border-radius: 4px;
            background: #0077b5;
            color: #fff;
            text-decoration: none;
            transition: opacity 0.2s;
          " target=_blank rel=noopener> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.06 2.06 0 0 1-2.063-2.065 2.064 2.064 0 1 1 2.063 2.065m1.782 13.019H3.555V9h3.564zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0z"/></svg> <span style="margin-left: 0.5rem">Share on LinkedIn</span> </a> </div> </div> <div class=newsletter-section style="margin: 2rem 0"> <script async data-uid=b184c2f91e src=https://ivan-leo.kit.com/b184c2f91e/index.js></script> </div> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": ["content.code.copy", "content.code.annotate", "navigation.tabs", "toc.follow", "navigation.path"], "search": "../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../assets/javascripts/bundle.83f73b43.min.js></script> <script src=../javascripts/mathjax.js></script> <script src=https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>